{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping is a way of extracting data from a website.\n",
    "<br>\n",
    "There are a few different library options to choose from such as requests and scrapy. \n",
    "<br>\n",
    "However, we have chosen to scrape using [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/).\n",
    "<br>\n",
    "To explore ways of using beautifulsoup, go directly to the documentation:\n",
    "<br>\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "<br>\n",
    "<br>\n",
    "In this session the aim was to scrape the website https://spreets.com.au/deals/sydney and to get the python console to only print a link to deals with greater than 70% off.\n",
    "<br>\n",
    "<br>\n",
    "First go to the website https://spreets.com.au/deals/sydney and right click to Inspect Element.\n",
    "<br>\n",
    "To get a handle on the tag terms a useful reference can be found here:\n",
    "<br>\n",
    "https://www.w3schools.com/tags/default.asp\n",
    "<br>\n",
    "<br>\n",
    "In the top left corner of Inspect Element, there is a small mouse icon that allows you to hover over an element on the website and the corresponding html code is highlighted accordingly.\n",
    "<br>\n",
    "Using this, we were able to identify the tags correlated with the deal %\n",
    "<br>\n",
    "![site_elements.png](https://raw.github.com/anniequasar/session-summaries/master/resources/img/site_elements.png)\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "First we need to import beautifulsoup by using the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to import a library that will open the link in python.\n",
    "<br>\n",
    "[urllib](https://docs.python.org/2/library/urllib.html) is a module that is split into 3 parts in python 3.\n",
    "<br>\n",
    "We can use the function urllib.request.urlopen() to open a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "page = urlopen(\"https://spreets.com.au/deals/sydney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code cell, I have made a variable called page.\n",
    "<br>\n",
    "Then I have called on the function urlopen from urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse a document aka \"make the soup\":\n",
    "<br>\n",
    "we use the command:\n",
    "<br> \n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to find all the links to the deals we use the function soup.find_all\n",
    "<br>\n",
    "When you hover your mouse over each deal using Inspect Element, you will find that the blue link with the deal % is inside the div tree so you need to move up the tree in order to extract the link.\n",
    "<br>\n",
    "Each deal sits inside the tag div.deal-list-wrapper\n",
    "<br>\n",
    "Each hyperlink with the deal \"Up to 00% Off\" has an em.discount tag\n",
    "<br>\n",
    "So to print a link of all the deals on the page that have deals >70% off, you could use an *if statement* inside a *for loop*.\n",
    "<br>\n",
    "First create a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divlist = soup.find_all(\"div\", \"deal-list-wrapper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a *for loop* using the syntax\n",
    "<br>\n",
    "        \n",
    "        for item in list:\n",
    "            execute command\n",
    "<br>\n",
    "Make a variable containing the string \"Up to 00% Off\" \n",
    "<br>\n",
    "In this case I have called it em and converted div.em into a string using the command em.string \n",
    "<br>\n",
    "Do you remember how to convert one data type into another?\n",
    "<br>\n",
    "By using:\n",
    "<br>\n",
    "str() to convert to a string\n",
    "<br>\n",
    "int() to convert to an integer\n",
    "<br>\n",
    "If this does not ring a bell, go back to [python_basics_summary.py](https://github.com/anniequasar/session-summaries/blob/master/2nd%20session/python_basics_summary.py)\n",
    "<br>\n",
    "Next, make a variable to tranform the datatype at the 6-8th index in the string \"Up to 00% Off\" using the int() command\n",
    "<br>\n",
    "Remember that python counts from zero and it counts white space as an index position as well.\n",
    "<br>\n",
    "Then if the integers in percentage (percentage is just a variable which you can call anything you like) is greater than 70 then print the link\n",
    "<br>\n",
    "<br>\n",
    "To get beautifulsoup to extract the link from the website, we used the function a.get(\"href\")\n",
    "<br>\n",
    "I remind you all the functions are in the [beautifulsoup documention!](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in divlist:\n",
    "\n",
    "    em = div.em\n",
    "\n",
    "    a = div.a\n",
    "\n",
    "    if em and \"%\" in em.string:\n",
    "\n",
    "        percentage = int(em.string[6:8])\n",
    "\n",
    "        if percentage > 70:\n",
    "            print(em.string)\n",
    "            print(\"Here is a link to the deal\")\n",
    "            print(a.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "To view this script in its entirety without all these instructions, download and run [webscraping.py](https://github.com/anniequasar/session-summaries/blob/master/3rd%20session/webscraping.py) in your IDE (PyCharm Edu)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
